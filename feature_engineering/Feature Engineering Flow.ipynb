{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "#from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n"
     ]
    }
   ],
   "source": [
    "print('Loading graph...')\n",
    "\n",
    "G_Whole =  nx.read_adjlist('../../train.txt', delimiter='\\t', create_using=nx.DiGraph(), nodetype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading partial graph...')\n",
    "\n",
    "#edges_subgraph = pd.read_csv('train_17MB.txt', header=None, names=['source','target','class'])\n",
    "#edges = edges_subgraph[edges_subgraph['class'] ==1]\n",
    "#edges_graph = edges[['source','target']]\n",
    "#edges_graph.to_csv('edges_graph.csv', header=False, index=None)\n",
    "G_limited =  nx.read_edgelist('edges_graph.csv',delimiter=',',create_using=nx.DiGraph(), nodetype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the graph (change to G_limited for the crawled subgraph)\n",
    "G = G_Whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' No longer in use (slow Pandas implementation)\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "features = np.array_split(dataset, 30)\n",
    "\n",
    "print('Splitting dataset into 30.')\n",
    "for i in tqdm(range(28,30)):\n",
    "    print('Dataset', i, '. number of samples:', len(features[i]))\n",
    "\n",
    "    features[i]['pref_attachment'] = features[i].apply(lambda row: pref_attach(row.source, row.target), axis=1)\n",
    "    features[i]['total_friends'] = features[i].apply(lambda row: total_friends(row.source, row.target), axis=1)\n",
    "    features[i]['common_friends'] = features[i].apply(lambda row: common_friends(row.source, row.target), axis=1)\n",
    "    features[i]['jacard_coef'] = features[i].apply(lambda row: jacard_coef(row.source, row.target), axis=1)\n",
    "    features[i].to_csv('data_features_%s.csv' % (i))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './../Data/sample.txt' # change to desired sampled dataset (remove header name because it's a string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have a class column \n",
    "train_data = np.loadtxt(file_path,  usecols=range(3))\n",
    "train_int = train_data.astype(np.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your file does not have class column, create one (assuming it's all existing edges, i.e. class 1)\n",
    "\n",
    "\n",
    "train_data = np.loadtxt(file_path, delimiter=',', usecols=range(2))\n",
    "\n",
    "classes = np.repeat(1, len(train_int))\n",
    "classes = classes.reshape(-1,1)\n",
    "train_int = np.append(train_int, classes, axis=1)\n",
    "train_int = train_int.astype(np.int64)\n",
    "#np.savetxt(file_path, train_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pasting features from file for faster Graph access. \n",
    "\n",
    "Feature function parameters are modified for a vectorised implementation.\n",
    "\n",
    "'''\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# Importing the features from Features2 file\n",
    "#from features2 import common_friends, jacard_coef, total_friends, trans_friends, opposite_friends, pref_attach\n",
    "\n",
    "\n",
    "# File for testing feature implementation\n",
    "import networkx as nx\n",
    "import time\n",
    "import pandas as pd\n",
    "#G =  nx.read_adjlist('/Users/williamrudd/documents/MSc/COMP90051/train.txt', delimiter='\\t',create_using=nx.DiGraph() )\n",
    "\n",
    "# Defining intersection and union of lists.\n",
    "#G.degree('20388')\n",
    "# Trying to be consistent with notation from the paper to avoid confusion.\n",
    "# Neighborhood functions\n",
    "def Gamma(u):\n",
    "    return set(G.successors(u)).union(G.predecessors(u))\n",
    "def Gamma_in(u):\n",
    "    return G.predecessors(u)\n",
    "def Gamma_out(u):\n",
    "    return G.successors(u)\n",
    "def Gamma_plus(u):\n",
    "    return set(Gamma(u)).union({u})\n",
    "\n",
    "\n",
    "## maybe not use.\n",
    "def Gamma_union(u):\n",
    "    return set(Gamma(u)).union(Gamma(u[1]))\n",
    "\n",
    "def Gamma_union_plus(u):\n",
    "    return set(Gamma_plus(u)).union(Gamma_plus(u[1]))\n",
    "# DEFINING FEATURES\n",
    "\n",
    "\n",
    "# FASTEST edge features => total of 4 features.\n",
    "def total_friends(x):\n",
    "    return len(set(Gamma(x[0])).union(Gamma(x[1])))\n",
    "# PREFERENTIAL ATTACHMENT\n",
    "def pref_attach(u):\n",
    "    return len(Gamma(u[0]))*len(Gamma(u[1]))\n",
    "\n",
    "# COMMON FRIENDS\n",
    "def common_friends(u):\n",
    "    return len(set(Gamma(u[0])).intersection(Gamma(u[1])))\n",
    "\n",
    "# JACARD'S COEFFICIENT\n",
    "def jacard_coef(u):\n",
    "    return common_friends(u)/total_friends(u)\n",
    "\n",
    "# TRANSITIVE FRIENDS\n",
    "def trans_friends(u):\n",
    "    return len(set(G.successors(u[0])).intersection(G.predecessors(u[1])))\n",
    "\n",
    "# OPPOSITE FRIENDS\n",
    "def opposite_friends(u):\n",
    "    return int(G.has_edge(u[1],u[0]))\n",
    "\n",
    "# Vertex features are all very fast and already implemented in networkx\n",
    "# example:\n",
    "#G.degree('20388')\n",
    "#G.in_degree('20388')\n",
    "#G.out_degree('20388')\n",
    "\n",
    "\n",
    "# SLOW FEATURES - need to be rewritten in a more efficient manner. To start, I will\n",
    "# be taking a look at\n",
    "\n",
    "def friends_measure(u):\n",
    "    counter = 0\n",
    "    for i in Gamma(u[0]):\n",
    "        for j in Gamma(u[1]):\n",
    "            if (i == j) or (G.has_edge(i,j) == True) or (G.has_edge(j,i) == True):\n",
    "                counter = counter + 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "# compute edge features\n",
    "\n",
    "# SUBGRAPH FUNCTIONS/FEATURES\n",
    "# I represent these in subgraph form rather than edge list, as specified in the\n",
    "# paper.\n",
    "\n",
    "# nh subgraph for vertex (unused as of this moment)\n",
    "def nh_subgraph_vertex(u):\n",
    "    return G.subgraph(Gamma(u[0]))\n",
    "\n",
    "def nh_subgraph_vertex_plus(u):\n",
    "    return G.subgraph(Gamma_plus(u[0]))\n",
    "\n",
    "# nh subgraph for edge\n",
    "def nh_subgraph_edge(u):\n",
    "    return G.subgraph(set(Gamma(u[0])).union(Gamma(u[1])))\n",
    "\n",
    "def nh_subgraph_edge_plus(u):\n",
    "    return G.subgraph(set(Gamma_plus(u[0])).union(Gamma_plus(u[1])))\n",
    "\n",
    "def inner_subgraph(u):\n",
    "    g1 = Gamma(u[0])\n",
    "    g2 = Gamma(u[1])\n",
    "    # some function that grabs a full edgelist\n",
    "    # for some edge (a,b)\n",
    "    g = nh_subgraph_edge(u[0])\n",
    "    e = g.edges()\n",
    "    inner = nx.DiGraph() # create empty subgraph structure\n",
    "    for i in e:\n",
    "        if ((i[0] in g1) and (i[1] in g2)) or ((i[1] in g1) and (i[0] in g2)):\n",
    "            inner.add_edge(i[0],i[1]) # add this edge to inner\n",
    "    return inner\n",
    "\n",
    "# scc nh subgraph\n",
    "def scc_nh(u):\n",
    "    return nx.number_strongly_connected_components(nh_subgraph_edge(u))\n",
    "\n",
    "# scc nh subgraph +\n",
    "def scc_nh_plus(u):\n",
    "    return nx.number_strongly_connected_components(nh_subgraph_edge_plus(u))\n",
    "\n",
    "# scc inner subgraph\n",
    "def scc_inner(u):\n",
    "    return nx.number_strongly_connected_components(inner_subgraph(u))\n",
    "\n",
    "\n",
    "# Related: number of nodes in the above subgraphs\n",
    "def size_nh(u):\n",
    "    return nx.number_of_nodes(nh_subgraph_edge(u))\n",
    "\n",
    "# size nh subgraph +\n",
    "def size_nh_plus(u):\n",
    "    return nx.number_of_nodes(nh_subgraph_edge_plus(u))\n",
    "\n",
    "# size inner subgraph\n",
    "def size_inner(u):\n",
    "    return nx.number_of_nodes(inner_subgraph(u))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friendship Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def features():\n",
    "    t0 = time.time()\n",
    "    common_friend = np.apply_along_axis(common_friends, 1, train_int)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total, total/len(train_int))\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_friend = np.apply_along_axis(total_friends, 1, train_int)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total, total/len(train_int))\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    jacard_coefs = common_friend / total_friend\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total, total/len(train_int))\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    trans_friend = np.apply_along_axis(trans_friends, 1, train_int)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total, total/len(train_int))\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    opposite_friend = np.apply_along_axis(opposite_friends, 1, train_int)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total, total/len(train_int))\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    prefs = np.apply_along_axis(pref_attach, 1, train_int)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total, total/len(train_int))\n",
    "    \n",
    "    return common_friend, jacard_coefs, total_friend, trans_friend, opposite_friend, prefs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_friend, jacard_coefs, total_friend, trans_friend, opposite_friend, prefs = features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute degree features\n",
    "def degree_features():\n",
    "    t = time.time()\n",
    "    degree_sources = np.apply_along_axis(G.degree, 0,train_int[:,:1])[1]\n",
    "    t1 = time.time() - t\n",
    "    print(t1)\n",
    "\n",
    "    t = time.time()\n",
    "    degree_source_in = np.apply_along_axis(G.in_degree,0,train_int[:,:1])[1]\n",
    "    t2 = time.time() - t\n",
    "    print(t2)\n",
    "\n",
    "    t = time.time()\n",
    "    degree_source_out = np.apply_along_axis( G.out_degree ,0,train_int[:,:1])[1]\n",
    "    t3 = time.time() - t\n",
    "    print(t3)\n",
    "\n",
    "    t = time.time()\n",
    "    degree_target = np.apply_along_axis(G.degree, 0,train_int[:,1:2])[1]\n",
    "    t4 = time.time() - t\n",
    "    print(t4)\n",
    "\n",
    "    t = time.time()\n",
    "    degree_target_in = np.apply_along_axis(G.in_degree,0,train_int[:,1:2])[1]\n",
    "    t5 = time.time() - t\n",
    "    print(t5)\n",
    "\n",
    "    t = time.time()\n",
    "    degree_target_out = np.apply_along_axis(G.out_degree,0,train_int[:,1:2])[1]\n",
    "    t6 = time.time() - t\n",
    "    print(t6)\n",
    "    \n",
    "    return degree_sources, degree_source_in, degree_source_out, degree_target, degree_target_in, degree_target_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sources, degree_source_in, degree_source_out, degree_target, degree_target_in, degree_target_out = degree_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this path name everytime you compute for a new dataset\n",
    "file_path = 'crawled_4_seeds'\n",
    "\n",
    "\n",
    "column_names = ['pref_attach','total_friends','common_friends','degree_source','degree_source_in','degree_source_out','degree_target','degree_target_in','degree_target_out','class']\n",
    "\n",
    "computed_features = pd.DataFrame(columns=column_names)\n",
    "computed_features['pref_attach'] = prefs\n",
    "computed_features['total_friends'] = total_friend\n",
    "computed_features['common_friends'] = common_friend\n",
    "computed_features['degree_source'] = degree_sources\n",
    "computed_features['degree_source_in'] = degree_source_in\n",
    "computed_features['degree_source_out'] = degree_source_out\n",
    "computed_features['degree_target'] = degree_target\n",
    "computed_features['degree_target_in'] = degree_target_in\n",
    "computed_features['degree_target_out'] = degree_target_out\n",
    "computed_features['class'] = train_int[:,2:3]\n",
    "\n",
    "computed_features.to_csv(str(file_path,'/train.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Individual Features (not in use) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G_limited\n",
    "file_path = 'crawled1_limited'\n",
    "features()\n",
    "np.savetxt(str(file_path,'/opposite_friends.txt'), opposite_friend)\n",
    "np.savetxt(str(file_path,'/friends.txt'), total_friend)\n",
    "np.savetxt(str(file_path,'/transistive_friends.txt'), trans_friend)\n",
    "np.savetxt(str(file_path,'/common_friends.txt'), common_friend)\n",
    "np.savetxt(str(file_path,'/preferential.txt'), prefs)\n",
    "np.savetxt(str(file_path,'/jaccards.txt'), jacard_coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G_Whole\n",
    "file_path = 'crawled1_whole'\n",
    "features()\n",
    "np.savetxt(str(file_path,'/opposite_friends.txt'), opposite_friend)\n",
    "np.savetxt(str(file_path,'/total_friends.txt'), total_friend)\n",
    "np.savetxt(str(file_path,'/transistive_friends.txt'), trans_friend)\n",
    "np.savetxt(str(file_path,'/common_friends.txt'), common_friend)\n",
    "np.savetxt(str(file_path,'/preferential.txt'), prefs)\n",
    "np.savetxt(str(file_path,'/jaccards.txt'), jacard_coefs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G_limited\n",
    "file_path = 'crawled1_limited'\n",
    "degree_features()\n",
    "np.savetxt(str(file_path,'/degree_sources.txt'), degree_sources[:,1])\n",
    "np.savetxt(str(file_path,'/degree_source_in.txt'), degree_source_in[:,1])\n",
    "np.savetxt(str(file_path,'/degree_source_out.txt'), degree_source_out[:,1])\n",
    "np.savetxt(str(file_path,'/degree_target.txt'), degree_target[:,1])\n",
    "np.savetxt(str(file_path,'/degree_target_in.txt'), degree_target_in[:,1])\n",
    "np.savetxt(str(file_path,'/degree_target_out.txt'), degree_target_out[:,1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G_Whole\n",
    "file_path = 'crawled1_whole'\n",
    "degree_features()\n",
    "\n",
    "np.savetxt(str(file_path,'/degree_sources.txt'), degree_sources[:,1])\n",
    "np.savetxt(str(file_path,'/degree_source_in.txt'), degree_source_in[:,1])\n",
    "np.savetxt(str(file_path,'/degree_source_out.txt'), degree_source_out[:,1])\n",
    "np.savetxt(str(file_path,'/degree_target.txt'), degree_target[:,1])\n",
    "np.savetxt(str(file_path,'/degree_target_in.txt'), degree_target_in[:,1])\n",
    "np.savetxt(str(file_path,'/degree_target_out.txt'), degree_target_out[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3567526"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
