{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Approach 1: Random 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Sampling approach 1:\n",
    "This implementation is: \n",
    "- randomly sampled without replacement(no feature distribution referred)\n",
    "- samples 5% of existing edges\n",
    "- samples 5% from \n",
    "\n",
    "Limitations:\n",
    "- did not create edges from target nodes to source nodes\n",
    "\n",
    "'''\n",
    "\n",
    "# data.csv is a list of the complete 24 million edges, modify to local path\n",
    "features_main = pd.read_csv('data.csv')\n",
    "features_main = features_main[['source','target']]\n",
    "\n",
    "# retrieving list of unique sources (not used here)\n",
    "sources = features_main[['source']]\n",
    "sources = sources.drop_duplicates()\n",
    "\n",
    "# retrieving list of unique targets\n",
    "targets = features_main['target']\n",
    "targets = targets.drop_duplicates()\n",
    "\n",
    "\n",
    "# [NOT USED] function to return a random target for a given source\n",
    "def unique_target(source):\n",
    "    #unique_targets = targets[~targets.isin(features_main.loc[(features_main['source'] == source), ['target']].target)]\n",
    "    return unique_targets.values[randint(0, len(unique_targets))]\n",
    "\n",
    "\n",
    "# sampling 5% of non existent edges from the global dataset then randomising target nodes\n",
    "class_0 = features_main.sample(frac=0.05, replace=False) \n",
    "#class_0['target'] = class_0.apply(lambda row: unique_target(row.source), axis = 1) # Not used\n",
    "class_0['target'] = targets.sample(len(class_0)).values\n",
    "class_0['class'] = 0\n",
    "class_0.to_csv('class_0.csv', index=False)\n",
    "\n",
    "# sampling 5% of existent edges from the global dataset \n",
    "class_1 = features_main.sample(frac=0.05, replace=False)\n",
    "class_1['class'] = 1\n",
    "class_1.to_csv('class_1.csv', index=False)\n",
    "\n",
    "# concatenating both classes\n",
    "dataset = pd.concat([class_1,class_0]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# shuffling \n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# saving the dataset\n",
    "dataset.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
